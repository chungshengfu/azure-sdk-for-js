/*
 * Copyright (c) Microsoft Corporation.
 * Licensed under the MIT License.
 *
 * Code generated by Microsoft (R) AutoRest Code Generator.
 * Changes may cause incorrect behavior and will be lost if the code is regenerated.
 */

import { PagedAsyncIterableIterator, PageSettings } from "@azure/core-paging";
import { setContinuationToken } from "../pagingHelper";
import { Connection } from "../operationsInterfaces";
import * as coreClient from "@azure/core-client";
import * as Mappers from "../models/mappers";
import * as Parameters from "../models/parameters";
import { AzureMachineLearningServices } from "../azureMachineLearningServices";
import {
  SimplePollerLike,
  OperationState,
  createHttpPoller,
} from "@azure/core-lro";
import { createLroSpec } from "../lroImpl";
import {
  EndpointDeploymentResourcePropertiesBasicResource,
  ConnectionListDeploymentsNextOptionalParams,
  ConnectionListDeploymentsOptionalParams,
  ConnectionListDeploymentsResponse,
  AccountModel,
  ConnectionGetModelsNextOptionalParams,
  ConnectionGetModelsOptionalParams,
  ConnectionGetModelsResponse,
  ConnectionDeleteDeploymentOptionalParams,
  ConnectionDeleteDeploymentResponse,
  ConnectionGetDeploymentOptionalParams,
  ConnectionGetDeploymentResponse,
  ConnectionCreateOrUpdateDeploymentOptionalParams,
  ConnectionCreateOrUpdateDeploymentResponse,
  ConnectionListDeploymentsNextResponse,
  ConnectionGetModelsNextResponse,
} from "../models";

/// <reference lib="esnext.asynciterable" />
/** Class containing Connection operations. */
export class ConnectionImpl implements Connection {
  private readonly client: AzureMachineLearningServices;

  /**
   * Initialize a new instance of the class Connection class.
   * @param client Reference to the service client
   */
  constructor(client: AzureMachineLearningServices) {
    this.client = client;
  }

  /**
   * Get all the deployments under the Azure OpenAI connection.
   * @param resourceGroupName The name of the resource group. The name is case insensitive.
   * @param workspaceName Azure Machine Learning Workspace Name
   * @param connectionName Friendly name of the workspace connection
   * @param options The options parameters.
   */
  public listDeployments(
    resourceGroupName: string,
    workspaceName: string,
    connectionName: string,
    options?: ConnectionListDeploymentsOptionalParams,
  ): PagedAsyncIterableIterator<EndpointDeploymentResourcePropertiesBasicResource> {
    const iter = this.listDeploymentsPagingAll(
      resourceGroupName,
      workspaceName,
      connectionName,
      options,
    );
    return {
      next() {
        return iter.next();
      },
      [Symbol.asyncIterator]() {
        return this;
      },
      byPage: (settings?: PageSettings) => {
        if (settings?.maxPageSize) {
          throw new Error("maxPageSize is not supported by this operation.");
        }
        return this.listDeploymentsPagingPage(
          resourceGroupName,
          workspaceName,
          connectionName,
          options,
          settings,
        );
      },
    };
  }

  private async *listDeploymentsPagingPage(
    resourceGroupName: string,
    workspaceName: string,
    connectionName: string,
    options?: ConnectionListDeploymentsOptionalParams,
    settings?: PageSettings,
  ): AsyncIterableIterator<
    EndpointDeploymentResourcePropertiesBasicResource[]
  > {
    let result: ConnectionListDeploymentsResponse;
    let continuationToken = settings?.continuationToken;
    if (!continuationToken) {
      result = await this._listDeployments(
        resourceGroupName,
        workspaceName,
        connectionName,
        options,
      );
      let page = result.value || [];
      continuationToken = result.nextLink;
      setContinuationToken(page, continuationToken);
      yield page;
    }
    while (continuationToken) {
      result = await this._listDeploymentsNext(
        resourceGroupName,
        workspaceName,
        connectionName,
        continuationToken,
        options,
      );
      continuationToken = result.nextLink;
      let page = result.value || [];
      setContinuationToken(page, continuationToken);
      yield page;
    }
  }

  private async *listDeploymentsPagingAll(
    resourceGroupName: string,
    workspaceName: string,
    connectionName: string,
    options?: ConnectionListDeploymentsOptionalParams,
  ): AsyncIterableIterator<EndpointDeploymentResourcePropertiesBasicResource> {
    for await (const page of this.listDeploymentsPagingPage(
      resourceGroupName,
      workspaceName,
      connectionName,
      options,
    )) {
      yield* page;
    }
  }

  /**
   * Get available models under the Azure OpenAI connection.
   * @param resourceGroupName The name of the resource group. The name is case insensitive.
   * @param workspaceName Azure Machine Learning Workspace Name
   * @param connectionName Friendly name of the workspace connection
   * @param options The options parameters.
   */
  public listModels(
    resourceGroupName: string,
    workspaceName: string,
    connectionName: string,
    options?: ConnectionGetModelsOptionalParams,
  ): PagedAsyncIterableIterator<AccountModel> {
    const iter = this.getModelsPagingAll(
      resourceGroupName,
      workspaceName,
      connectionName,
      options,
    );
    return {
      next() {
        return iter.next();
      },
      [Symbol.asyncIterator]() {
        return this;
      },
      byPage: (settings?: PageSettings) => {
        if (settings?.maxPageSize) {
          throw new Error("maxPageSize is not supported by this operation.");
        }
        return this.getModelsPagingPage(
          resourceGroupName,
          workspaceName,
          connectionName,
          options,
          settings,
        );
      },
    };
  }

  private async *getModelsPagingPage(
    resourceGroupName: string,
    workspaceName: string,
    connectionName: string,
    options?: ConnectionGetModelsOptionalParams,
    settings?: PageSettings,
  ): AsyncIterableIterator<AccountModel[]> {
    let result: ConnectionGetModelsResponse;
    let continuationToken = settings?.continuationToken;
    if (!continuationToken) {
      result = await this._getModels(
        resourceGroupName,
        workspaceName,
        connectionName,
        options,
      );
      let page = result.value || [];
      continuationToken = result.nextLink;
      setContinuationToken(page, continuationToken);
      yield page;
    }
    while (continuationToken) {
      result = await this._getModelsNext(
        resourceGroupName,
        workspaceName,
        connectionName,
        continuationToken,
        options,
      );
      continuationToken = result.nextLink;
      let page = result.value || [];
      setContinuationToken(page, continuationToken);
      yield page;
    }
  }

  private async *getModelsPagingAll(
    resourceGroupName: string,
    workspaceName: string,
    connectionName: string,
    options?: ConnectionGetModelsOptionalParams,
  ): AsyncIterableIterator<AccountModel> {
    for await (const page of this.getModelsPagingPage(
      resourceGroupName,
      workspaceName,
      connectionName,
      options,
    )) {
      yield* page;
    }
  }

  /**
   * Get all the deployments under the Azure OpenAI connection.
   * @param resourceGroupName The name of the resource group. The name is case insensitive.
   * @param workspaceName Azure Machine Learning Workspace Name
   * @param connectionName Friendly name of the workspace connection
   * @param options The options parameters.
   */
  private _listDeployments(
    resourceGroupName: string,
    workspaceName: string,
    connectionName: string,
    options?: ConnectionListDeploymentsOptionalParams,
  ): Promise<ConnectionListDeploymentsResponse> {
    return this.client.sendOperationRequest(
      { resourceGroupName, workspaceName, connectionName, options },
      listDeploymentsOperationSpec,
    );
  }

  /**
   * Delete Azure OpenAI connection deployment resource by name
   * @param resourceGroupName The name of the resource group. The name is case insensitive.
   * @param workspaceName Azure Machine Learning Workspace Name
   * @param connectionName Friendly name of the workspace connection
   * @param deploymentName Name of the deployment resource
   * @param options The options parameters.
   */
  async beginDeleteDeployment(
    resourceGroupName: string,
    workspaceName: string,
    connectionName: string,
    deploymentName: string,
    options?: ConnectionDeleteDeploymentOptionalParams,
  ): Promise<
    SimplePollerLike<
      OperationState<ConnectionDeleteDeploymentResponse>,
      ConnectionDeleteDeploymentResponse
    >
  > {
    const directSendOperation = async (
      args: coreClient.OperationArguments,
      spec: coreClient.OperationSpec,
    ): Promise<ConnectionDeleteDeploymentResponse> => {
      return this.client.sendOperationRequest(args, spec);
    };
    const sendOperationFn = async (
      args: coreClient.OperationArguments,
      spec: coreClient.OperationSpec,
    ) => {
      let currentRawResponse: coreClient.FullOperationResponse | undefined =
        undefined;
      const providedCallback = args.options?.onResponse;
      const callback: coreClient.RawResponseCallback = (
        rawResponse: coreClient.FullOperationResponse,
        flatResponse: unknown,
      ) => {
        currentRawResponse = rawResponse;
        providedCallback?.(rawResponse, flatResponse);
      };
      const updatedArgs = {
        ...args,
        options: {
          ...args.options,
          onResponse: callback,
        },
      };
      const flatResponse = await directSendOperation(updatedArgs, spec);
      return {
        flatResponse,
        rawResponse: {
          statusCode: currentRawResponse!.status,
          body: currentRawResponse!.parsedBody,
          headers: currentRawResponse!.headers.toJSON(),
        },
      };
    };

    const lro = createLroSpec({
      sendOperationFn,
      args: {
        resourceGroupName,
        workspaceName,
        connectionName,
        deploymentName,
        options,
      },
      spec: deleteDeploymentOperationSpec,
    });
    const poller = await createHttpPoller<
      ConnectionDeleteDeploymentResponse,
      OperationState<ConnectionDeleteDeploymentResponse>
    >(lro, {
      restoreFrom: options?.resumeFrom,
      intervalInMs: options?.updateIntervalInMs,
      resourceLocationConfig: "location",
    });
    await poller.poll();
    return poller;
  }

  /**
   * Delete Azure OpenAI connection deployment resource by name
   * @param resourceGroupName The name of the resource group. The name is case insensitive.
   * @param workspaceName Azure Machine Learning Workspace Name
   * @param connectionName Friendly name of the workspace connection
   * @param deploymentName Name of the deployment resource
   * @param options The options parameters.
   */
  async beginDeleteDeploymentAndWait(
    resourceGroupName: string,
    workspaceName: string,
    connectionName: string,
    deploymentName: string,
    options?: ConnectionDeleteDeploymentOptionalParams,
  ): Promise<ConnectionDeleteDeploymentResponse> {
    const poller = await this.beginDeleteDeployment(
      resourceGroupName,
      workspaceName,
      connectionName,
      deploymentName,
      options,
    );
    return poller.pollUntilDone();
  }

  /**
   * Get deployments under the Azure OpenAI connection by name.
   * @param resourceGroupName The name of the resource group. The name is case insensitive.
   * @param workspaceName Azure Machine Learning Workspace Name
   * @param connectionName Friendly name of the workspace connection
   * @param deploymentName Name of the deployment resource
   * @param options The options parameters.
   */
  getDeployment(
    resourceGroupName: string,
    workspaceName: string,
    connectionName: string,
    deploymentName: string,
    options?: ConnectionGetDeploymentOptionalParams,
  ): Promise<ConnectionGetDeploymentResponse> {
    return this.client.sendOperationRequest(
      {
        resourceGroupName,
        workspaceName,
        connectionName,
        deploymentName,
        options,
      },
      getDeploymentOperationSpec,
    );
  }

  /**
   * Create or update Azure OpenAI connection deployment resource with the specified parameters
   * @param resourceGroupName The name of the resource group. The name is case insensitive.
   * @param workspaceName Azure Machine Learning Workspace Name
   * @param connectionName Friendly name of the workspace connection
   * @param deploymentName Name of the deployment resource
   * @param body deployment object
   * @param options The options parameters.
   */
  async beginCreateOrUpdateDeployment(
    resourceGroupName: string,
    workspaceName: string,
    connectionName: string,
    deploymentName: string,
    body: EndpointDeploymentResourcePropertiesBasicResource,
    options?: ConnectionCreateOrUpdateDeploymentOptionalParams,
  ): Promise<
    SimplePollerLike<
      OperationState<ConnectionCreateOrUpdateDeploymentResponse>,
      ConnectionCreateOrUpdateDeploymentResponse
    >
  > {
    const directSendOperation = async (
      args: coreClient.OperationArguments,
      spec: coreClient.OperationSpec,
    ): Promise<ConnectionCreateOrUpdateDeploymentResponse> => {
      return this.client.sendOperationRequest(args, spec);
    };
    const sendOperationFn = async (
      args: coreClient.OperationArguments,
      spec: coreClient.OperationSpec,
    ) => {
      let currentRawResponse: coreClient.FullOperationResponse | undefined =
        undefined;
      const providedCallback = args.options?.onResponse;
      const callback: coreClient.RawResponseCallback = (
        rawResponse: coreClient.FullOperationResponse,
        flatResponse: unknown,
      ) => {
        currentRawResponse = rawResponse;
        providedCallback?.(rawResponse, flatResponse);
      };
      const updatedArgs = {
        ...args,
        options: {
          ...args.options,
          onResponse: callback,
        },
      };
      const flatResponse = await directSendOperation(updatedArgs, spec);
      return {
        flatResponse,
        rawResponse: {
          statusCode: currentRawResponse!.status,
          body: currentRawResponse!.parsedBody,
          headers: currentRawResponse!.headers.toJSON(),
        },
      };
    };

    const lro = createLroSpec({
      sendOperationFn,
      args: {
        resourceGroupName,
        workspaceName,
        connectionName,
        deploymentName,
        body,
        options,
      },
      spec: createOrUpdateDeploymentOperationSpec,
    });
    const poller = await createHttpPoller<
      ConnectionCreateOrUpdateDeploymentResponse,
      OperationState<ConnectionCreateOrUpdateDeploymentResponse>
    >(lro, {
      restoreFrom: options?.resumeFrom,
      intervalInMs: options?.updateIntervalInMs,
      resourceLocationConfig: "location",
    });
    await poller.poll();
    return poller;
  }

  /**
   * Create or update Azure OpenAI connection deployment resource with the specified parameters
   * @param resourceGroupName The name of the resource group. The name is case insensitive.
   * @param workspaceName Azure Machine Learning Workspace Name
   * @param connectionName Friendly name of the workspace connection
   * @param deploymentName Name of the deployment resource
   * @param body deployment object
   * @param options The options parameters.
   */
  async beginCreateOrUpdateDeploymentAndWait(
    resourceGroupName: string,
    workspaceName: string,
    connectionName: string,
    deploymentName: string,
    body: EndpointDeploymentResourcePropertiesBasicResource,
    options?: ConnectionCreateOrUpdateDeploymentOptionalParams,
  ): Promise<ConnectionCreateOrUpdateDeploymentResponse> {
    const poller = await this.beginCreateOrUpdateDeployment(
      resourceGroupName,
      workspaceName,
      connectionName,
      deploymentName,
      body,
      options,
    );
    return poller.pollUntilDone();
  }

  /**
   * Get available models under the Azure OpenAI connection.
   * @param resourceGroupName The name of the resource group. The name is case insensitive.
   * @param workspaceName Azure Machine Learning Workspace Name
   * @param connectionName Friendly name of the workspace connection
   * @param options The options parameters.
   */
  private _getModels(
    resourceGroupName: string,
    workspaceName: string,
    connectionName: string,
    options?: ConnectionGetModelsOptionalParams,
  ): Promise<ConnectionGetModelsResponse> {
    return this.client.sendOperationRequest(
      { resourceGroupName, workspaceName, connectionName, options },
      getModelsOperationSpec,
    );
  }

  /**
   * ListDeploymentsNext
   * @param resourceGroupName The name of the resource group. The name is case insensitive.
   * @param workspaceName Azure Machine Learning Workspace Name
   * @param connectionName Friendly name of the workspace connection
   * @param nextLink The nextLink from the previous successful call to the ListDeployments method.
   * @param options The options parameters.
   */
  private _listDeploymentsNext(
    resourceGroupName: string,
    workspaceName: string,
    connectionName: string,
    nextLink: string,
    options?: ConnectionListDeploymentsNextOptionalParams,
  ): Promise<ConnectionListDeploymentsNextResponse> {
    return this.client.sendOperationRequest(
      { resourceGroupName, workspaceName, connectionName, nextLink, options },
      listDeploymentsNextOperationSpec,
    );
  }

  /**
   * GetModelsNext
   * @param resourceGroupName The name of the resource group. The name is case insensitive.
   * @param workspaceName Azure Machine Learning Workspace Name
   * @param connectionName Friendly name of the workspace connection
   * @param nextLink The nextLink from the previous successful call to the GetModels method.
   * @param options The options parameters.
   */
  private _getModelsNext(
    resourceGroupName: string,
    workspaceName: string,
    connectionName: string,
    nextLink: string,
    options?: ConnectionGetModelsNextOptionalParams,
  ): Promise<ConnectionGetModelsNextResponse> {
    return this.client.sendOperationRequest(
      { resourceGroupName, workspaceName, connectionName, nextLink, options },
      getModelsNextOperationSpec,
    );
  }
}
// Operation Specifications
const serializer = coreClient.createSerializer(Mappers, /* isXml */ false);

const listDeploymentsOperationSpec: coreClient.OperationSpec = {
  path: "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/connections/{connectionName}/deployments",
  httpMethod: "GET",
  responses: {
    200: {
      bodyMapper:
        Mappers.EndpointDeploymentResourcePropertiesBasicResourceArmPaginatedResult,
    },
    default: {
      bodyMapper: Mappers.ErrorResponse,
    },
  },
  queryParameters: [Parameters.apiVersion],
  urlParameters: [
    Parameters.$host,
    Parameters.subscriptionId,
    Parameters.resourceGroupName,
    Parameters.workspaceName,
    Parameters.connectionName,
  ],
  headerParameters: [Parameters.accept],
  serializer,
};
const deleteDeploymentOperationSpec: coreClient.OperationSpec = {
  path: "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/connections/{connectionName}/deployments/{deploymentName}",
  httpMethod: "DELETE",
  responses: {
    200: {
      headersMapper: Mappers.ConnectionDeleteDeploymentHeaders,
    },
    201: {
      headersMapper: Mappers.ConnectionDeleteDeploymentHeaders,
    },
    202: {
      headersMapper: Mappers.ConnectionDeleteDeploymentHeaders,
    },
    204: {
      headersMapper: Mappers.ConnectionDeleteDeploymentHeaders,
    },
    default: {
      bodyMapper: Mappers.ErrorResponse,
    },
  },
  queryParameters: [Parameters.apiVersion],
  urlParameters: [
    Parameters.$host,
    Parameters.subscriptionId,
    Parameters.resourceGroupName,
    Parameters.workspaceName,
    Parameters.connectionName,
    Parameters.deploymentName2,
  ],
  headerParameters: [Parameters.accept],
  serializer,
};
const getDeploymentOperationSpec: coreClient.OperationSpec = {
  path: "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/connections/{connectionName}/deployments/{deploymentName}",
  httpMethod: "GET",
  responses: {
    200: {
      bodyMapper: Mappers.EndpointDeploymentResourcePropertiesBasicResource,
    },
    default: {
      bodyMapper: Mappers.ErrorResponse,
    },
  },
  queryParameters: [Parameters.apiVersion],
  urlParameters: [
    Parameters.$host,
    Parameters.subscriptionId,
    Parameters.resourceGroupName,
    Parameters.workspaceName,
    Parameters.connectionName,
    Parameters.deploymentName2,
  ],
  headerParameters: [Parameters.accept],
  serializer,
};
const createOrUpdateDeploymentOperationSpec: coreClient.OperationSpec = {
  path: "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/connections/{connectionName}/deployments/{deploymentName}",
  httpMethod: "PUT",
  responses: {
    200: {
      bodyMapper: Mappers.EndpointDeploymentResourcePropertiesBasicResource,
    },
    201: {
      bodyMapper: Mappers.EndpointDeploymentResourcePropertiesBasicResource,
    },
    202: {
      bodyMapper: Mappers.EndpointDeploymentResourcePropertiesBasicResource,
    },
    204: {
      bodyMapper: Mappers.EndpointDeploymentResourcePropertiesBasicResource,
    },
    default: {
      bodyMapper: Mappers.ErrorResponse,
    },
  },
  requestBody: Parameters.body50,
  queryParameters: [Parameters.apiVersion],
  urlParameters: [
    Parameters.$host,
    Parameters.subscriptionId,
    Parameters.resourceGroupName,
    Parameters.workspaceName,
    Parameters.connectionName,
    Parameters.deploymentName2,
  ],
  headerParameters: [Parameters.accept, Parameters.contentType],
  mediaType: "json",
  serializer,
};
const getModelsOperationSpec: coreClient.OperationSpec = {
  path: "/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/connections/{connectionName}/models",
  httpMethod: "GET",
  responses: {
    200: {
      bodyMapper: Mappers.EndpointModels,
    },
    default: {
      bodyMapper: Mappers.ErrorResponse,
    },
  },
  queryParameters: [Parameters.apiVersion],
  urlParameters: [
    Parameters.$host,
    Parameters.subscriptionId,
    Parameters.resourceGroupName,
    Parameters.workspaceName,
    Parameters.connectionName,
  ],
  headerParameters: [Parameters.accept],
  serializer,
};
const listDeploymentsNextOperationSpec: coreClient.OperationSpec = {
  path: "{nextLink}",
  httpMethod: "GET",
  responses: {
    200: {
      bodyMapper:
        Mappers.EndpointDeploymentResourcePropertiesBasicResourceArmPaginatedResult,
    },
    default: {
      bodyMapper: Mappers.ErrorResponse,
    },
  },
  urlParameters: [
    Parameters.$host,
    Parameters.subscriptionId,
    Parameters.nextLink,
    Parameters.resourceGroupName,
    Parameters.workspaceName,
    Parameters.connectionName,
  ],
  headerParameters: [Parameters.accept],
  serializer,
};
const getModelsNextOperationSpec: coreClient.OperationSpec = {
  path: "{nextLink}",
  httpMethod: "GET",
  responses: {
    200: {
      bodyMapper: Mappers.EndpointModels,
    },
    default: {
      bodyMapper: Mappers.ErrorResponse,
    },
  },
  urlParameters: [
    Parameters.$host,
    Parameters.subscriptionId,
    Parameters.nextLink,
    Parameters.resourceGroupName,
    Parameters.workspaceName,
    Parameters.connectionName,
  ],
  headerParameters: [Parameters.accept],
  serializer,
};
